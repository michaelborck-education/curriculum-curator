"""
Unit tests for LLM service
"""

import pytest
from unittest.mock import Mock, patch, AsyncMock
from app.services.llm_service import LLMService


class TestLLMService:
    """Test LLM service functionality"""

    def test_llm_service_initialization(self):
        """Test LLM service initialization"""
        service = LLMService()
        assert service is not None
        assert isinstance(service.providers, dict)

    def test_check_providers_without_keys(self):
        """Test provider checking without API keys"""
        with patch.dict("os.environ", {}, clear=True):
            service = LLMService()
            # Should not have any providers enabled without API keys
            assert len(service.providers) == 0

    def test_check_providers_with_openai_key(self):
        """Test provider checking with OpenAI API key"""
        with patch.dict("os.environ", {"OPENAI_API_KEY": "test-key"}):
            service = LLMService()
            assert "openai" in service.providers
            assert service.providers["openai"] is True

    def test_check_providers_with_anthropic_key(self):
        """Test provider checking with Anthropic API key"""
        with patch.dict("os.environ", {"ANTHROPIC_API_KEY": "test-key"}):
            service = LLMService()
            assert "anthropic" in service.providers
            assert service.providers["anthropic"] is True

    def test_get_system_settings(self):
        """Test getting system settings from database"""
        service = LLMService()

        # Mock database session
        mock_db = Mock()
        mock_settings = [
            Mock(key="default_llm_provider", value="openai"),
            Mock(key="default_llm_model", value="gpt-4"),
            Mock(key="system_openai_api_key", value="system-key"),
        ]

        mock_db.query.return_value.filter.return_value.all.return_value = mock_settings

        settings = service._get_system_settings(mock_db)

        assert settings["default_llm_provider"] == "openai"
        assert settings["default_llm_model"] == "gpt-4"
        assert settings["system_openai_api_key"] == "system-key"

    def test_get_user_api_key(self):
        """Test extracting user API key from config"""
        service = LLMService()

        user_config = {
            "openai_api_key": "user-openai-key",
            "anthropic_api_key": "user-anthropic-key",
            "gemini_api_key": "user-gemini-key",
        }

        # Test OpenAI key extraction
        key = service._get_user_api_key("openai", user_config)
        assert key == "user-openai-key"

        # Test Anthropic key extraction
        key = service._get_user_api_key("anthropic", user_config)
        assert key == "user-anthropic-key"

        # Test Gemini key extraction
        key = service._get_user_api_key("gemini", user_config)
        assert key == "user-gemini-key"

        # Test unknown provider
        key = service._get_user_api_key("unknown", user_config)
        assert key is None

    def test_get_system_api_key(self):
        """Test getting system API key"""
        service = LLMService()

        system_settings = {
            "system_openai_api_key": "system-openai-key",
            "system_anthropic_api_key": "system-anthropic-key",
        }

        # Mock settings module
        with patch("app.services.llm_service.settings") as mock_settings:
            mock_settings.OPENAI_API_KEY = "env-openai-key"
            mock_settings.ANTHROPIC_API_KEY = "env-anthropic-key"

            # Test with system key available
            key = service._get_system_api_key("openai", system_settings)
            assert key == "system-openai-key"

            # Test with only env key available
            system_settings_no_openai = {
                "system_anthropic_api_key": "system-anthropic-key"
            }
            key = service._get_system_api_key("openai", system_settings_no_openai)
            assert key == "env-openai-key"

            # Test with no key available
            key = service._get_system_api_key("unknown", system_settings)
            assert key is None

    @pytest.mark.asyncio
    async def test_generate_text(self):
        """Test text generation"""
        service = LLMService()

        # Mock litellm acompletion
        mock_response = Mock()
        mock_response.choices = [Mock(message=Mock(content="Test response"))]

        with patch(
            "app.services.llm_service.acompletion", new_callable=AsyncMock
        ) as mock_acompletion:
            mock_acompletion.return_value = mock_response

            # Mock provider check
            service.providers = {"openai": True}

            # Mock settings
            with patch("app.services.llm_service.settings") as mock_settings:
                mock_settings.OPENAI_API_KEY = "test-key"

                # Mock database session
                mock_db = Mock()
                mock_db.query.return_value.filter.return_value.all.return_value = []

                # Mock user
                mock_user = Mock()
                mock_user.llm_config = {}

                # Test text generation
                result = await service.generate_text(
                    prompt="Test prompt", user=mock_user, db=mock_db
                )
                assert result == "Test response"

    def test_estimate_tokens(self):
        """Test token estimation"""
        service = LLMService()

        # Test with simple text
        text = "Hello world"
        tokens = service.estimate_tokens(text)
        assert isinstance(tokens, int)
        assert tokens > 0

        # Test with longer text
        long_text = "Hello world " * 100
        tokens_long = service.estimate_tokens(long_text)
        assert tokens_long > tokens

        # Test with empty text
        tokens_empty = service.estimate_tokens("")
        assert tokens_empty == 0

    def test_estimate_cost(self):
        """Test cost calculation"""
        service = LLMService()

        # Test cost estimation
        cost = service.estimate_cost(1000, 500, "gpt-4")
        assert isinstance(cost, float)
        assert cost >= 0

        # Test with different model
        cost = service.estimate_cost(1000, 500, "claude-3-sonnet")
        assert isinstance(cost, float)
        assert cost >= 0

    @pytest.mark.asyncio
    async def test_test_connection(self):
        """Test connection testing"""
        service = LLMService()

        # Mock litellm completion
        with patch("app.services.llm_service.completion") as mock_completion:
            mock_completion.return_value = Mock(
                choices=[Mock(message=Mock(content="pong"))]
            )

            # Mock provider check
            service.providers = {"openai": True}

            # Mock settings
            with patch("app.services.llm_service.settings") as mock_settings:
                mock_settings.OPENAI_API_KEY = "test-key"

                result = await service.test_connection("openai", "gpt-4")
                assert result["success"] is True
                assert "pong" in result["response"].lower()

                # Test with failed connection
                mock_completion.side_effect = Exception("Connection failed")
                result = await service.test_connection("openai", "gpt-4")
                assert result["success"] is False
                assert "Connection failed" in result["error"]

    @pytest.mark.asyncio
    async def test_list_available_models(self):
        """Test getting available models"""
        service = LLMService()

        # Mock provider check
        service.providers = {"openai": True, "anthropic": True}

        models = await service.list_available_models()

        assert isinstance(models, list)
        # Should contain at least the default models
        assert any("gpt" in model.lower() for model in models)
        assert any("claude" in model.lower() for model in models)


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
